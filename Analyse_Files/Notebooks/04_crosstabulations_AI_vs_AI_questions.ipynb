{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95652542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SETUP BLOCK\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency, spearmanr, fisher_exact\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from Helper_functions import (\n",
    "    clean_up_subjects,\n",
    "    calculate_true_false_score,\n",
    "    calculate_internet_terms_understanding_score,\n",
    "    group_internet_understanding,\n",
    "    prepare_pair,\n",
    "    order_crosstab,\n",
    ")\n",
    "\n",
    "from lists import (\n",
    "    multiple_choice_questions,\n",
    "    LIKERT_VALUE_MAPS,\n",
    "    comparison_pairs_by_AI_questions,\n",
    "    cross_tab_titles_and_colors,\n",
    ")\n",
    "\n",
    "from answer_categories import question_orders, COLUMN_ALIASES\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "DATA_FILE = os.path.join(\"..\", \"Data\", \"Fertige Tabelle.xlsx\")\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "df = df.rename(columns=COLUMN_ALIASES)\n",
    "\n",
    "for col in [\"Most used subjects\", \"Preferred Subjects\", \"Least preferred Subjects\"]:\n",
    "    if col in df.columns:\n",
    "        df = clean_up_subjects(df, col)\n",
    "\n",
    "true_false_cols = [f\"True/False_{i}\" for i in range(1, 7)]\n",
    "if all(c in df.columns for c in true_false_cols):\n",
    "    df = calculate_true_false_score(df)\n",
    "\n",
    "if any(c.startswith(\"Internet terms_\") for c in df.columns):\n",
    "    df = calculate_internet_terms_understanding_score(df)\n",
    "    df = group_internet_understanding(df)\n",
    "\n",
    "print(\"Setup complete – DataFrame loaded and preprocessed\")\n",
    "print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BUILD COUNT COLUMNS FROM MULTI-CHOICE TEXT\n",
    "# ==========================================\n",
    "\n",
    "# count column based on number of answers given in MC question\n",
    "def build_count_from_multichoice(df_in: pd.DataFrame, source_col: str, new_col: str) -> pd.DataFrame:\n",
    "   \n",
    "    if source_col not in df_in.columns:\n",
    "        print(f\"Source column '{source_col}' not in DataFrame; cannot build '{new_col}'.\")\n",
    "        return df_in\n",
    "\n",
    "    def _count_items(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        s = str(x).strip()\n",
    "        if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "            return np.nan\n",
    "\n",
    "        s = s.replace(\";\", \",\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "        parts = [p.strip() for p in s.split(\",\")]\n",
    "        parts = [p for p in parts if p]\n",
    "\n",
    "        seen = set()\n",
    "        unique_parts = []\n",
    "        for p in parts:\n",
    "            if p not in seen:\n",
    "                seen.add(p)\n",
    "                unique_parts.append(p)\n",
    "        return len(unique_parts) if unique_parts else np.nan\n",
    "\n",
    "    df_in[new_col] = df_in[source_col].apply(_count_items).astype(\"Int64\")\n",
    "    print(f\"✅ Built count column '{new_col}' from '{source_col}'.\")\n",
    "    return df_in\n",
    "\n",
    "\n",
    "df = build_count_from_multichoice(df, \"Reasons to use AI\", \"Reasons to use AI (Count)\")\n",
    "\n",
    "df = build_count_from_multichoice(df, \"Purposes to use AI\", \"Purposes to use AI (Count)\")\n",
    "\n",
    "\n",
    "try:\n",
    "    min_c = int(df[\"Reasons to use AI (Count)\"].min())\n",
    "    max_c = int(df[\"Reasons to use AI (Count)\"].max())\n",
    "    question_orders[\"Reasons to use AI (Count)\"] = list(range(min_c, max_c + 1))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    min_c = int(df[\"Purposes to use AI (Count)\"].min())\n",
    "    max_c = int(df[\"Purposes to use AI (Count)\"].max())\n",
    "    question_orders[\"Purposes to use AI (Count)\"] = list(range(min_c, max_c + 1))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAR CHARTS (COUNTS, stacked)\n",
    "# ==========================================\n",
    "\n",
    "for base_question, compare_list in comparison_pairs_by_AI_questions.items():\n",
    "    for compare_question in compare_list:\n",
    "\n",
    "        left_is_multi = base_question in multiple_choice_questions\n",
    "        right_is_multi = compare_question in multiple_choice_questions\n",
    "\n",
    "        data = prepare_pair(df, base_question, compare_question, left_is_multi, right_is_multi)\n",
    "        if data.empty:\n",
    "            print(f\"No overlapping data for '{base_question}' × '{compare_question}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        ct = pd.crosstab(data[base_question], data[compare_question])\n",
    "\n",
    "        if not ct.columns.is_unique:\n",
    "            ct = ct.T.groupby(level=0).sum().T\n",
    "        if not ct.index.is_unique:\n",
    "            ct = ct.groupby(level=0).sum()\n",
    "\n",
    "\n",
    "        ct = order_crosstab(ct, base_question, compare_question)\n",
    "        if ct.empty:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{compare_question} within each {base_question} (counts)\")\n",
    "        print(ct)\n",
    "\n",
    "        title_and_colors = cross_tab_titles_and_colors.get(\n",
    "            (base_question, compare_question),\n",
    "            [f\"{compare_question} within each {base_question} (stacked counts)\"]\n",
    "        )\n",
    "        plot_title = title_and_colors[0]\n",
    "\n",
    "        blue_palette = sns.color_palette(\"Blues\", n_colors=max(3, min(7, ct.shape[1])))\n",
    "\n",
    "        if len(title_and_colors) > 1:\n",
    "            ax = ct.plot(kind=\"bar\", stacked=True, figsize=(10, 6), color=title_and_colors[1:], width=0.9)\n",
    "        else:\n",
    "            ax = ct.plot(kind=\"bar\", stacked=True, figsize=(10, 6), color=blue_palette, width=0.9)\n",
    "\n",
    "        ax.set_title(plot_title)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_xlabel(base_question)\n",
    "\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.legend(title=compare_question, bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SIGNIFICANCE TESTS for AI × AI crosstabs\n",
    "# ==========================================\n",
    "\n",
    "def cramers_v_corrected(chi2, ct):\n",
    "    n = ct.values.sum()\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    r, k = ct.shape\n",
    "    phi2 = chi2 / n\n",
    "    if n > 1:\n",
    "        phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "        rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "        kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "    else:\n",
    "        phi2corr, rcorr, kcorr = np.nan, r, k\n",
    "    denom = min(rcorr - 1, kcorr - 1)\n",
    "    return np.sqrt(phi2corr / denom) if denom > 0 else np.nan\n",
    "\n",
    "ai_ai_tests = []\n",
    "\n",
    "for base_question, compare_list in comparison_pairs_by_AI_questions.items():\n",
    "    for compare_question in compare_list:\n",
    "\n",
    "        left_is_multi = base_question in multiple_choice_questions\n",
    "        right_is_multi = compare_question in multiple_choice_questions\n",
    "\n",
    "        data = prepare_pair(df, base_question, compare_question, left_is_multi, right_is_multi)\n",
    "        if data.empty:\n",
    "            continue\n",
    "\n",
    "        ct = pd.crosstab(data[base_question], data[compare_question])\n",
    "\n",
    "        if not ct.columns.is_unique:\n",
    "            ct = ct.T.groupby(level=0).sum().T\n",
    "        if not ct.index.is_unique:\n",
    "            ct = ct.groupby(level=0).sum()\n",
    "\n",
    "        ct = order_crosstab(ct, base_question, compare_question)\n",
    "\n",
    "        ct = ct.loc[ct.sum(axis=1) > 0, ct.sum(axis=0) > 0]\n",
    "        if ct.shape[0] < 2 or ct.shape[1] < 2:\n",
    "            continue\n",
    "\n",
    "        chi2, p, dof, expected = chi2_contingency(ct.values, correction=False)\n",
    "        expected_df = pd.DataFrame(expected, index=ct.index, columns=ct.columns)\n",
    "\n",
    "        v = cramers_v_corrected(chi2, ct)\n",
    "        min_exp = float(expected_df.values.min())\n",
    "        prop_lt5 = float((expected_df.values < 5).mean())\n",
    "        n_total = int(ct.values.sum())\n",
    "\n",
    "        ai_ai_tests.append({\n",
    "            \"base_question\": base_question,\n",
    "            \"compare_question\": compare_question,\n",
    "            \"n\": n_total,\n",
    "            \"rows\": ct.shape[0],\n",
    "            \"cols\": ct.shape[1],\n",
    "            \"chi2\": float(chi2),\n",
    "            \"dof\": int(dof),\n",
    "            \"p\": float(p),\n",
    "            \"cramers_v\": float(v),\n",
    "            \"min_expected\": min_exp,\n",
    "            \"prop_expected_lt5\": prop_lt5,\n",
    "        })\n",
    "\n",
    "ai_ai_tests_df = (\n",
    "    pd.DataFrame(ai_ai_tests)\n",
    "    .sort_values([\"base_question\", \"compare_question\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"AI×AI significance finished. Total tests: {len(ai_ai_tests_df)}\")\n",
    "\n",
    "EXPORT = True\n",
    "EXPORT_PATH = os.path.join(\"..\", \"Data\", \"test_results\", \"ai_ai_chi_square_results.xlsx\")\n",
    "if EXPORT:\n",
    "    with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as writer:\n",
    "        ai_ai_tests_df.to_excel(writer, index=False, sheet_name=\"chi_square_results\")\n",
    "    print(f\"Exported to: {EXPORT_PATH}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59442d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SPEARMAN TREND TESTS (ordinal × ordinal)\n",
    "# ==========================================\n",
    "\n",
    "def map_to_numeric_flexible(series, varname):\n",
    "    s = series.astype(\"string\").str.strip()\n",
    "\n",
    "    if varname in LIKERT_VALUE_MAPS:\n",
    "        mp = {str(k): v for k, v in LIKERT_VALUE_MAPS[varname].items()}\n",
    "        out = s.map(mp)\n",
    "        if out.notna().any():\n",
    "            return out.astype(float)\n",
    "\n",
    "    if varname in question_orders:\n",
    "        order = [str(x) for x in question_orders[varname]]\n",
    "        mapper = {cat: i for i, cat in enumerate(order)}\n",
    "        out = s.map(mapper)\n",
    "        if out.notna().any():\n",
    "            return out.astype(float)\n",
    "\n",
    "    return pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "def run_spearman_pair(df_in, x, y):\n",
    "    if x not in df_in.columns or y not in df_in.columns:\n",
    "        return None\n",
    "\n",
    "    if (x in multiple_choice_questions and \"(Count)\" not in x) or (y in multiple_choice_questions and \"(Count)\" not in y):\n",
    "        return None\n",
    "\n",
    "    X = map_to_numeric_flexible(df_in[x], x)\n",
    "    Y = map_to_numeric_flexible(df_in[y], y)\n",
    "    data = pd.DataFrame({\"x\": X, \"y\": Y}).dropna()\n",
    "    if data.empty:\n",
    "        return None\n",
    "\n",
    "    rho, p = spearmanr(data[\"x\"].values, data[\"y\"].values)\n",
    "    return {\"x\": x, \"y\": y, \"n\": int(len(data)), \"rho\": float(rho), \"p\": float(p),\n",
    "            \"direction\": \"positive\" if rho > 0 else (\"negative\" if rho < 0 else \"zero\")}\n",
    "\n",
    "spearman_pairs = [\n",
    "    (\"Use AI school and freetime\", \"Usefulness AI\"),\n",
    "    (\"Use AI school and freetime\", \"Reliability AI\"),\n",
    "    (\"Use AI school and freetime\", \"Mates using AI\"),\n",
    "    (\"Use AI school and freetime\", \"Deal with AI\"),\n",
    "    (\"Reliability AI\", \"Teachers preparing lessons\"),\n",
    "    (\"Reliability AI\", \"Teachers giving grades\"),\n",
    "    (\"Frequency use of AI_school\", \"Help of AI\"),\n",
    "    (\"Frequency use of AI_school\", \"Reasons to use AI (Count)\"),\n",
    "    (\"Frequency use of AI_school\", \"Purposes to use AI (Count)\"),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for x, y in spearman_pairs:\n",
    "    out = run_spearman_pair(df, x, y)\n",
    "    if out:\n",
    "        rows.append(out)\n",
    "\n",
    "spearman_summary = pd.DataFrame(rows).sort_values([\"x\",\"y\"]).reset_index(drop=True)\n",
    "print(f\"Spearman tests completed: {len(spearman_summary)}\")\n",
    "\n",
    "EXPORT = True\n",
    "EXPORT_PATH = os.path.join(\"..\", \"Data\", \"test_results\", \"ai_ai_spearman_trends.xlsx\")\n",
    "if EXPORT:\n",
    "    with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as writer:\n",
    "        spearman_summary.to_excel(writer, index=False, sheet_name=\"spearman_trends\")\n",
    "    print(f\"Exported to: {EXPORT_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PAIRWISE 2×2 TESTS (auto Fisher or Chi-square)\n",
    "# ==========================================\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def test_2x2(a, b, c, d, alternative=\"two-sided\", prefer=\"auto\", yates=False):\n",
    "    table = np.array([[int(a), int(b)], [int(c), int(d)]], dtype=int)\n",
    "\n",
    "    row_sums = table.sum(axis=1)\n",
    "    col_sums = table.sum(axis=0)\n",
    "    if (row_sums[0] == 0) or (row_sums[1] == 0) or (col_sums[0] == 0) or (col_sums[1] == 0):\n",
    "        return {\"method\": \"skip\", \"p\": np.nan, \"chi2\": np.nan, \"dof\": 1, \"odds_ratio\": np.nan}\n",
    "\n",
    "    N = table.sum()\n",
    "    expected = np.outer(row_sums, col_sums) / N\n",
    "    min_exp = expected.min()\n",
    "\n",
    "    method = \"chi2\"\n",
    "    if prefer == \"fisher\" or (prefer == \"auto\" and (min_exp < 5 or (table == 0).any())):\n",
    "        method = \"fisher\"\n",
    "\n",
    "    if method == \"fisher\":\n",
    "        orat, p = fisher_exact(table, alternative=alternative)\n",
    "        return {\"method\": \"fisher\", \"p\": float(p), \"chi2\": np.nan, \"dof\": 1, \"odds_ratio\": float(orat) if np.isfinite(orat) else np.nan}\n",
    "\n",
    "    chi2_val, p, dof, _ = chi2_contingency(table, correction=yates)\n",
    "\n",
    "    a_, b_, c_, d_ = table.astype(float).ravel()\n",
    "    if 0 in (a_, b_, c_, d_):\n",
    "        a_, b_, c_, d_ = a_ + 0.5, b_ + 0.5, c_ + 0.5, d_ + 0.5\n",
    "    odds_ratio = (a_ * d_) / (b_ * c_)\n",
    "\n",
    "    return {\"method\": \"chi2\", \"p\": float(p), \"chi2\": float(chi2_val), \"dof\": int(dof), \"odds_ratio\": float(odds_ratio)}\n",
    "\n",
    "def pairwise_2x2_for_pair(df_in, left, right, prefer=\"auto\", yates=False):\n",
    "    left_is_multi = left in multiple_choice_questions\n",
    "    right_is_multi = right in multiple_choice_questions\n",
    "\n",
    "    data = prepare_pair(df_in, left, right, left_is_multi, right_is_multi)\n",
    "    if data.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ct = pd.crosstab(data[left], data[right])\n",
    "    if not ct.columns.is_unique:\n",
    "        ct = ct.T.groupby(level=0).sum().T\n",
    "    if not ct.index.is_unique:\n",
    "        ct = ct.groupby(level=0).sum()\n",
    "\n",
    "    ct = order_crosstab(ct, left, right)\n",
    "    ct = ct.loc[ct.sum(axis=1) > 0, ct.sum(axis=0) > 0]\n",
    "    if ct.shape[0] < 1 or ct.shape[1] < 2:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    totals = ct.sum(axis=0)\n",
    "    rows = []\n",
    "\n",
    "    for row_cat in ct.index:\n",
    "        for g1, g2 in combinations(ct.columns, 2):\n",
    "            a = int(ct.loc[row_cat, g1]); b = int(totals[g1] - a)\n",
    "            c = int(ct.loc[row_cat, g2]); d = int(totals[g2] - c)\n",
    "            res = test_2x2(a, b, c, d, prefer=prefer, yates=yates)\n",
    "\n",
    "            rows.append({\n",
    "                \"left_var\": left,\n",
    "                \"right_var\": right,\n",
    "                \"row_cat\": row_cat,\n",
    "                \"g1\": g1,\n",
    "                \"g2\": g2,\n",
    "                \"method\": res[\"method\"],\n",
    "                \"p\": res[\"p\"],\n",
    "                \"chi2\": res[\"chi2\"],\n",
    "                \"dof\": res[\"dof\"],\n",
    "                \"odds_ratio\": res[\"odds_ratio\"],\n",
    "                \"n_g1\": int(totals[g1]),\n",
    "                \"n_g2\": int(totals[g2]),\n",
    "                \"x_g1\": a,\n",
    "                \"x_g2\": c,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "pairwise_2x2_pairs = [\n",
    "    (\"Use AI school and freetime\", \"Concerns AI\"),\n",
    "    (\"Used AI\", \"Reliability AI\"),\n",
    "]\n",
    "\n",
    "all_2x2 = []\n",
    "for left, right in pairwise_2x2_pairs:\n",
    "    out = pairwise_2x2_for_pair(df, left, right, prefer=\"auto\", yates=False)\n",
    "    if not out.empty:\n",
    "        all_2x2.append(out)\n",
    "\n",
    "pairwise_results = pd.concat(all_2x2, ignore_index=True) if all_2x2 else pd.DataFrame()\n",
    "print(f\"Pairwise 2×2 tests completed: {len(pairwise_results)}\")\n",
    "\n",
    "EXPORT = True\n",
    "EXPORT_PATH = os.path.join(\"..\", \"Data\", \"test_results\", \"ai_ai_posthoc_nominal_2x2.xlsx\")\n",
    "if EXPORT:\n",
    "    with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as writer:\n",
    "        pairwise_results.to_excel(writer, index=False, sheet_name=\"pairwise_2x2_tests\")\n",
    "    print(f\"Exported to: {EXPORT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
