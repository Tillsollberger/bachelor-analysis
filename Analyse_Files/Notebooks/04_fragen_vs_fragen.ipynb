{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95652542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SETUP BLOCK \n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---- Imports from project files ----\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from Helper_funtions import (\n",
    "    clean_up_subjects,\n",
    "    calculate_true_false_score,\n",
    "    calculate_Internet_terms_understanding_score,\n",
    "    group_internet_understanding\n",
    ")\n",
    "from lists import (\n",
    "    demographic_columns,\n",
    "    multiple_choice_questions,\n",
    "    single_choice_questions,\n",
    "    likert_questions,\n",
    "    likert_mapping,\n",
    "    comparison_pairs_by_AI_questions,\n",
    "    cross_tab_titles_and_colors\n",
    "\n",
    ")\n",
    "from answer_categories import question_orders\n",
    "\n",
    "# ---- General plot style ----\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# ---- Data loading ----\n",
    "DATA_FILE = os.path.join(\"..\", \"Data\", \"Fertige Tabelle.xlsx\")\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean up multi-subject columns\n",
    "for col in [\"Most used subjects\", \"Preferred Subjects\", \"Least preferred Subjects\"]:\n",
    "    if col in df.columns:\n",
    "        df = clean_up_subjects(df, col)\n",
    "\n",
    "# Calculate additional scores\n",
    "if all(q in df.columns for q in [\"True/False_1\", \"True/False_2\"]):\n",
    "    df = calculate_true_false_score(df)\n",
    "\n",
    "if any(col.startswith(\"Internet terms_\") for col in df.columns):\n",
    "    df = calculate_Internet_terms_understanding_score(df)\n",
    "    df = group_internet_understanding(df)\n",
    "\n",
    "print(\"‚úÖ Setup complete ‚Äì DataFrame loaded and preprocessed\")\n",
    "print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e999cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- cross-tables with graphs, graphs with seperated bars -------\n",
    "\n",
    "for demo, question_list in comparison_pairs_by_AI_questions.items(): \n",
    "    for question in question_list:\n",
    "        try:\n",
    "            relevant_cols = [demo, question]\n",
    "            data = df[relevant_cols].dropna()\n",
    "\n",
    "            # Handle exploding if any of the two is multiple choice\n",
    "            for col in relevant_cols:\n",
    "                if col in multiple_choice_questions:\n",
    "                    data[col] = data[col].astype(str).str.split(\",\")\n",
    "                    data = data.explode(col)\n",
    "                    data[col] = data[col].str.strip()\n",
    "\n",
    "            # Drop any remaining empty entries\n",
    "            data = data.dropna()\n",
    "            data = data[(data[demo].astype(str).str.strip() != \"\") & (data[question].astype(str).str.strip() != \"\")]\n",
    "\n",
    "            # Crosstab normalized by row (percentages)\n",
    "            cross = pd.crosstab(data[demo], data[question], normalize='index') * 100\n",
    "\n",
    "            # Apply predefined order\n",
    "            if question in question_orders:\n",
    "                order = question_orders[question]\n",
    "                for col in order:\n",
    "                    if col not in cross.columns:\n",
    "                        cross[col] = 0\n",
    "                cross = cross[order]\n",
    "\n",
    "            if pd.api.types.is_numeric_dtype(data[demo]):\n",
    "                cross = cross.sort_index()\n",
    "\n",
    "            print(f\"\\nüìä {question} grouped by {demo}\")\n",
    "            print(cross.round(1).to_string())\n",
    "\n",
    "            # Plot\n",
    "            plot_df = cross.reset_index().melt(id_vars=demo, var_name=\"Answer\", value_name=\"Percentage\")\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(data=plot_df, x=\"Answer\", y=\"Percentage\", hue=demo)\n",
    "            plt.title(f\"{question} grouped by {demo}\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Test failed for {question} x {demo}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ significance tests, tables, and stacked graphs with 100% bars -------\n",
    "\n",
    "# Helper: align two columns on the same rows and explode when needed\n",
    "def build_pair_dataframe(df_in: pd.DataFrame, left: str, right: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with two cleaned columns [left, right], where:\n",
    "      - multiple-choice columns are split on ',' and exploded\n",
    "      - empty/whitespace-only values are removed\n",
    "      - both columns come from the same row slice to keep alignment\n",
    "    \"\"\"\n",
    "    left_is_multi  = left  in multiple_choice_questions\n",
    "    right_is_multi = right in multiple_choice_questions\n",
    "\n",
    "    tmp = df_in[[left, right]].dropna().copy()\n",
    "\n",
    "    if left_is_multi:\n",
    "        tmp[left] = tmp[left].astype(str).str.split(\",\")\n",
    "    else:\n",
    "        tmp[left] = tmp[left].astype(str).str.strip()\n",
    "\n",
    "    if right_is_multi:\n",
    "        tmp[right] = tmp[right].astype(str).str.split(\",\")\n",
    "    else:\n",
    "        tmp[right] = tmp[right].astype(str).str.strip()\n",
    "\n",
    "    # explode whichever needs exploding (order matters: explode one, then the other)\n",
    "    if left_is_multi:\n",
    "        tmp = tmp.explode(left)\n",
    "    if right_is_multi:\n",
    "        tmp = tmp.explode(right)\n",
    "\n",
    "    # strip again (post-explode) and drop truly empty\n",
    "    tmp[left]  = tmp[left].astype(str).str.strip()\n",
    "    tmp[right] = tmp[right].astype(str).str.strip()\n",
    "    tmp = tmp[(tmp[left] != \"\") & (tmp[right] != \"\")]\n",
    "\n",
    "    return tmp\n",
    "\n",
    "# Helper: apply ordering with question_orders or numeric\n",
    "def order_rows_cols(ct: pd.DataFrame, rows_key: str, cols_key: str) -> pd.DataFrame:\n",
    "    # columns (answers of \"right\" question)\n",
    "    if cols_key in question_orders:\n",
    "        col_order = [v for v in question_orders[cols_key] if v in ct.columns]\n",
    "        remaining_cols = [v for v in ct.columns if v not in col_order]\n",
    "        ct = ct[col_order + remaining_cols]\n",
    "    else:\n",
    "        # numeric fallback for columns\n",
    "        try:\n",
    "            _ = pd.to_numeric(ct.columns)\n",
    "            ct = ct[sorted(ct.columns, key=lambda x: float(x))]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # rows (answers of \"left\" question)\n",
    "    if rows_key in question_orders:\n",
    "        row_order = [v for v in question_orders[rows_key] if v in ct.index]\n",
    "        remaining_rows = [v for v in ct.index if v not in row_order]\n",
    "        ct = ct.reindex(row_order + remaining_rows)\n",
    "    else:\n",
    "        # numeric fallback for rows\n",
    "        try:\n",
    "            ct.index = pd.to_numeric(ct.index)\n",
    "            ct = ct.sort_index()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return ct\n",
    "\n",
    "# Main loop: for each AI base question, compare to each AI question\n",
    "for base_question, compare_list in comparison_pairs_by_AI_questions.items():\n",
    "    for compare_question in compare_list:\n",
    "        try:\n",
    "            # Build pair-wise dataset (handles single/multiple and alignment)\n",
    "            data = build_pair_dataframe(df, base_question, compare_question)\n",
    "            if data.empty:\n",
    "                print(f\"‚ö†Ô∏è No overlapping data for '{base_question}' x '{compare_question}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Crosstab: rows = base question categories, cols = compare question categories\n",
    "            ct = pd.crosstab(data[base_question], data[compare_question])\n",
    "\n",
    "            # Fold duplicates (rare: if hidden whitespace produced duplicate labels)\n",
    "            if not ct.columns.is_unique:\n",
    "                ct = ct.T.groupby(level=0).sum().T\n",
    "            if not ct.index.is_unique:\n",
    "                ct = ct.groupby(level=0).sum()\n",
    "\n",
    "            # Apply predefined ordering (or numeric as fallback)\n",
    "            ct = order_rows_cols(ct, rows_key=base_question, cols_key=compare_question)\n",
    "\n",
    "            # Normalize each row (each bar = 100%)\n",
    "            ct_percent = (ct.div(ct.sum(axis=1), axis=0) * 100).fillna(0)\n",
    "\n",
    "            # ---- Chi-square test on counts (NOT on percentages) ----\n",
    "            # Filter out rows with zero total (rare)\n",
    "            ct_for_test = ct.loc[ct.sum(axis=1) > 0]\n",
    "            significant = None\n",
    "            if ct_for_test.shape[0] >= 2 and ct_for_test.shape[1] >= 2:\n",
    "                chi2, p, dof, expected = chi2_contingency(ct_for_test)\n",
    "                significant = (p < 0.05)\n",
    "                print(f\"\\nüîç Chi¬≤-test: {base_question} √ó {compare_question} | chi¬≤={chi2:.3f}, df={dof}, p={p:.4f} ‚Üí \"\n",
    "                      f\"{'‚úÖ significant' if significant else '‚ùå not significant'}\")\n",
    "            else:\n",
    "                print(f\"\\n‚ÑπÔ∏è Chi¬≤-test skipped for '{base_question} √ó {compare_question}' (table too small).\")\n",
    "\n",
    "            # ---- Tabular printout (Counts & %) ----\n",
    "            print(f\"\\nüìä {compare_question} within each {base_question} (rows sum to 100%)\")\n",
    "            print(\"Counts:\\n\", ct)\n",
    "            print(\"\\nPercent:\\n\", ct_percent.round(1))\n",
    "\n",
    "            # ---- Plot: stacked 100% bar (X = base_question categories, stacks = compare_question answers) ----\n",
    "            title_and_colors = cross_tab_titles_and_colors_ai.get(\n",
    "                (base_question, compare_question),\n",
    "                [f\"{compare_question} within each {base_question} (100% stacked)\"]\n",
    "            )\n",
    "            plot_title = title_and_colors[0]\n",
    "\n",
    "            blues_palette = sns.color_palette(\"Blues\", n_colors=5)\n",
    "\n",
    "            ax = None\n",
    "            if len(title_and_colors) > 1:\n",
    "                # explicit colors supplied\n",
    "                colors = title_and_colors[1:]\n",
    "                ax = ct_percent.plot(kind=\"bar\", stacked=True, figsize=(10, 6), color=colors, width=0.9)\n",
    "            else:\n",
    "                # default palette\n",
    "                ax = ct_percent.plot(kind=\"bar\", stacked=True, figsize=(10, 6), color=sns.color_palette(\"Blues\", n_colors=len(ct_percent.columns)), width=0.9)\n",
    "\n",
    "            ax.set_title(plot_title)\n",
    "            ax.set_ylabel(\"Percentage (%)\")\n",
    "            ax.set_xlabel(base_question)\n",
    "            ax.set_ylim(0, 100)\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.legend(title=compare_question, bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed for {base_question} x {compare_question}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
