{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SETUP BLOCK \n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# ---- Imports from project files ----\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from Helper_funtions import (\n",
    "    clean_up_subjects,\n",
    "    calculate_true_false_score,\n",
    "    calculate_Internet_terms_understanding_score,\n",
    "    group_internet_understanding\n",
    ")\n",
    "from lists import (\n",
    "    demographic_columns,\n",
    "    multiple_choice_questions,\n",
    "    single_choice_questions,\n",
    "    likert_questions,\n",
    "    likert_mapping,\n",
    "    cross_tab_titles_and_colors\n",
    "\n",
    ")\n",
    "from answer_categories import question_orders\n",
    "\n",
    "# ---- General plot style ----\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# ---- Data loading ----\n",
    "DATA_FILE = os.path.join(\"..\", \"Data\", \"Fertige Tabelle.xlsx\")\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean up multi-subject columns\n",
    "for col in [\"Most used subjects\", \"Preferred Subjects\", \"Least preferred Subjects\"]:\n",
    "    if col in df.columns:\n",
    "        df = clean_up_subjects(df, col)\n",
    "\n",
    "# Calculate additional scores\n",
    "if all(q in df.columns for q in [\"True/False_1\", \"True/False_2\"]):\n",
    "    df = calculate_true_false_score(df)\n",
    "\n",
    "if any(col.startswith(\"Internet terms_\") for col in df.columns):\n",
    "    df = calculate_Internet_terms_understanding_score(df)\n",
    "    df = group_internet_understanding(df)\n",
    "\n",
    "print(\"‚úÖ Setup complete ‚Äì DataFrame loaded and preprocessed\")\n",
    "print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Creation of Clusters and Excel file \"Clustered_Students\" ----------\n",
    "\n",
    "# Keep only rows that have *all* likert features present\n",
    "df_clean = df.dropna(subset=likert_questions).copy()\n",
    "\n",
    "# Replace Likert-scale labels with numeric values where needed.\n",
    "# Numeric columns (like True_False_Score) will pass through unchanged.\n",
    "df_numeric = (\n",
    "    df_clean[likert_questions]\n",
    "    .apply(lambda s: s.astype(object))          # kategoriellen dtype aufbrechen\n",
    "    .replace(likert_mapping)\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")      # sicher numerisch\n",
    ")\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Show PCA loadings (influence of each question on the principal components)\n",
    "components = pd.DataFrame(pca.components_, columns=likert_questions, index=[\"PC1\", \"PC2\"])\n",
    "print(\"üìä PCA loadings ‚Äì influence of questions on components:\")\n",
    "print(components.T)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(pca_result)\n",
    "\n",
    "# Add clusters back to cleaned DataFrame\n",
    "df_clean[\"Cluster\"] = clusters\n",
    "\n",
    "# Create a PCA scatter plot with clusters\n",
    "df_plot = pd.DataFrame(pca_result, columns=[\"PC1\", \"PC2\"])\n",
    "df_plot[\"Cluster\"] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=df_plot, x=\"PC1\", y=\"PC2\", hue=\"Cluster\", palette=\"tab10\", s=100)\n",
    "plt.title(\"PCA of AI Attitudes (KMeans Clustering)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Cluster\", loc=\"best\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Mean values per cluster (how the clusters answered each Likert question)\n",
    "cluster_means = (\n",
    "    df_numeric.assign(Cluster=df_clean[\"Cluster\"])\n",
    "    .groupby(\"Cluster\")\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Mean scores of Likert questions per cluster:\")\n",
    "print(cluster_means.T)\n",
    "\n",
    "# Plot heatmap of cluster means\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_means.T, annot=True, cmap=\"YlGnBu\", linewidths=0.5)\n",
    "plt.title(\"Cluster Profiles based on Likert-scale Answers\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Question\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Export: jedes Cluster als eigenes Sheet in Clustered_Students.xlsx ---\n",
    "\n",
    "# Zielpfad anlegen\n",
    "out_dir = os.path.join(\"..\", \"Data\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"Clustered_Students.xlsx\")\n",
    "\n",
    "# (Optional) Cluster-Spalte als erste Spalte setzen\n",
    "export_cols = [\"Cluster\"] + [c for c in df_clean.columns if c != \"Cluster\"]\n",
    "df_export = df_clean[export_cols].copy()\n",
    "\n",
    "# Schreiben: ein Sheet pro Cluster\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:  # engine kann auch \"xlsxwriter\" sein\n",
    "    for c in sorted(df_export[\"Cluster\"].unique()):\n",
    "        sheet_name = f\"Cluster_{c}\"[:31]  # Excel-Limit: 31 Zeichen\n",
    "        df_cluster = df_export[df_export[\"Cluster\"] == c]\n",
    "        df_cluster.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"‚úÖ Exportiert: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric[likert_questions].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26743ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Analysis of the seperate clusters -------\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Dateien\n",
    "cluster_file = os.path.join(\"..\", \"Data\", \"Clustered_Students.xlsx\")\n",
    "full_data_file = os.path.join(\"..\", \"Data\", \"Fertige Tabelle.xlsx\")\n",
    "\n",
    "# Daten laden\n",
    "df_total = pd.read_excel(full_data_file)\n",
    "df_total.columns = df_total.columns.str.strip()\n",
    "\n",
    "# alle Cluster-Sheets laden (ein Sheet = ein Cluster)\n",
    "xls = pd.read_excel(cluster_file, sheet_name=None)\n",
    "\n",
    "def _to_str_clean(s):\n",
    "    \"\"\"Hilfsfunktion: NaNs droppen, zu String, trimmen.\"\"\"\n",
    "    return s.dropna().astype(str).str.strip()\n",
    "\n",
    "def _explode_if_multiple(df, col):\n",
    "    \"\"\"Explode f√ºr Multiple-Choice-Spalten (kommagetrennt).\"\"\"\n",
    "    tmp = df[[col]].copy()\n",
    "    tmp = tmp.dropna()\n",
    "    # falls Eintr√§ge schon Listen sind ‚Üí direkt explodieren, sonst splitten\n",
    "    if tmp[col].map(lambda x: isinstance(x, (list, tuple))).any():\n",
    "        exploded = tmp.explode(col)\n",
    "    else:\n",
    "        exploded = tmp.assign(**{col: tmp[col].astype(str).str.split(\",\")}).explode(col)\n",
    "    exploded[col] = exploded[col].astype(str).str.strip()\n",
    "    exploded = exploded[exploded[col] != \"\"]\n",
    "    return exploded[col]\n",
    "\n",
    "def _apply_order(df, col):\n",
    "    \"\"\"Index nach question_orders (falls vorhanden) oder numerisch sortieren.\"\"\"\n",
    "    if col in question_orders:\n",
    "        order = [str(v) for v in question_orders[col] if str(v) in df.index]\n",
    "        return df.reindex(order)\n",
    "    # numerische Sortierung, wenn Index rein numerisch ist\n",
    "    if df.index.to_series().str.fullmatch(r\"-?\\d+(\\.\\d+)?\").all():\n",
    "        return df.sort_index(key=lambda x: x.astype(float))\n",
    "    return df\n",
    "\n",
    "# ---------- Analyse pro Cluster ----------\n",
    "for sheet_name, cluster_df in xls.items():\n",
    "    print(f\"\\n================  {sheet_name}  ================\")\n",
    "\n",
    "    for column in demographic_columns:\n",
    "        if column not in df_total.columns:\n",
    "            print(f\"‚ö†Ô∏è Spalte '{column}' nicht im Gesamtdatensatz. √úberspringe.\")\n",
    "            continue\n",
    "        if column not in cluster_df.columns:\n",
    "            print(f\"‚ö†Ô∏è Spalte '{column}' nicht im Cluster-Sheet. √úberspringe.\")\n",
    "            continue\n",
    "\n",
    "        # --- Series vorbereiten (Single vs Multiple Choice) ---\n",
    "        if column in multiple_choice_questions:\n",
    "            cluster_series = _explode_if_multiple(cluster_df, column)\n",
    "            total_series   = _explode_if_multiple(df_total, column)\n",
    "        else:\n",
    "            cluster_series = _to_str_clean(cluster_df[column])\n",
    "            total_series   = _to_str_clean(df_total[column])\n",
    "\n",
    "        # Kategorie-Level vereinheitlichen (alle Kategorien aus total als Basis)\n",
    "        total_counts = total_series.value_counts(dropna=False)\n",
    "        cluster_counts = cluster_series.value_counts(dropna=False)\n",
    "\n",
    "        # --- (A) Cluster composition: % within the cluster ---\n",
    "        # Share of each category within the given cluster\n",
    "        cluster_comp_pct = (cluster_counts / cluster_counts.sum() * 100).reindex(total_counts.index).fillna(0).round(1)\n",
    "\n",
    "        table_cluster_comp = pd.DataFrame({\n",
    "            f\"{sheet_name} Count\": cluster_counts.reindex(total_counts.index).fillna(0).astype(int),\n",
    "            f\"{sheet_name} % (within cluster)\": cluster_comp_pct\n",
    "        })\n",
    "        table_cluster_comp = _apply_order(table_cluster_comp, column)\n",
    "\n",
    "        print(f\"\\nüìä {column} ‚Äì Distribution in {sheet_name}\")\n",
    "        display(HTML(table_cluster_comp.style.format(precision=1).set_caption(f\"{column} ‚Äì {sheet_name}: Cluster-Komposition\").to_html()))\n",
    "\n",
    "        # Plot A\n",
    "        plt.figure(figsize=(9, 4))\n",
    "        sns.barplot(x=table_cluster_comp.index, y=table_cluster_comp[f\"{sheet_name} % (within cluster)\"], palette=\"Set2\")\n",
    "        plt.title(f\"{column} ‚Äì {sheet_name}: % of students in cluster\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Prozent (%)\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.ylim(0, 100)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- (B) Category coverage of the cluster: % of the category in the cluster ---\n",
    "        # Share of students with category k who are in this cluster\n",
    "        # (Cluster_k / Total_k) * 100\n",
    "        percent_of_category_in_cluster = (cluster_counts / total_counts * 100).reindex(total_counts.index).fillna(0).round(1)\n",
    "\n",
    "        table_cat_capture = pd.DataFrame({\n",
    "            \"Total Count\": total_counts.astype(int),\n",
    "            f\"{sheet_name} Count\": cluster_counts.reindex(total_counts.index).fillna(0).astype(int),\n",
    "            f\"% of {column} in {sheet_name}\": percent_of_category_in_cluster\n",
    "        })\n",
    "        table_cat_capture = _apply_order(table_cat_capture, column)\n",
    "\n",
    "        print(f\"\\nüìà {column} ‚Äì % of the category in {sheet_name}:\")\n",
    "        display(HTML(table_cat_capture.style.format(precision=1).set_caption(f\"{column} ‚Äì Anteil der Kategorie im {sheet_name}\").to_html()))\n",
    "\n",
    "        # Plot B\n",
    "        plt.figure(figsize=(9, 4))\n",
    "        sns.barplot(x=table_cat_capture.index, y=table_cat_capture[f\"% of {column} in {sheet_name}\"], palette=\"Set2\")\n",
    "        plt.title(f\"{column} ‚Äì % of the category in {sheet_name}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Prozent (%)\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.ylim(0, 100)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
