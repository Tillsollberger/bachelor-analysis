{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SETUP BLOCK \n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---- Imports from project files ----\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from Helper_funtions import (\n",
    "    clean_up_subjects,\n",
    "    calculate_true_false_score,\n",
    "    calculate_Internet_terms_understanding_score,\n",
    "    group_internet_understanding\n",
    ")\n",
    "from lists import (\n",
    "    demographic_columns,\n",
    "    multiple_choice_questions,\n",
    "    single_choice_questions,\n",
    "    likert_questions,\n",
    "    likert_mapping,\n",
    "    comparison_pairs_by_demo,\n",
    "    cross_tab_titles_and_colors,\n",
    "    nominal_posthoc_pairs_demo,\n",
    "    ordinal_posthoc_pairs_demo\n",
    ")\n",
    "from answer_categories import question_orders\n",
    "\n",
    "# ---- General plot style ----\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# ---- Data loading ----\n",
    "DATA_FILE = os.path.join(\"..\", \"Data\", \"Fertige Tabelle.xlsx\")\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean up multi-subject columns\n",
    "for col in [\"Most used subjects\", \"Preferred Subjects\", \"Least preferred Subjects\"]:\n",
    "    if col in df.columns:\n",
    "        df = clean_up_subjects(df, col)\n",
    "\n",
    "# Calculate additional scores\n",
    "if all(q in df.columns for q in [\"True/False_1\", \"True/False_2\"]):\n",
    "    df = calculate_true_false_score(df)\n",
    "\n",
    "if any(col.startswith(\"Internet terms_\") for col in df.columns):\n",
    "    df = calculate_Internet_terms_understanding_score(df)\n",
    "    df = group_internet_understanding(df)\n",
    "\n",
    "print(\"âœ… Setup complete â€“ DataFrame loaded and preprocessed\")\n",
    "print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6100059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- selected cross-tabulations with stacked bar plots ------\n",
    "\n",
    "multiple_choice_demographics = {\n",
    "    \"Preferred Subjects\",\n",
    "    \"Least preferred Subjects\",\n",
    "    \"Most used subjects\",\n",
    "}\n",
    "\n",
    "# ---------- Helper: Spalte ggf. split/explode + leere Werte droppen ----------\n",
    "def prepare_column(df_in, col, is_multi):\n",
    "    if is_multi:\n",
    "        tmp = (\n",
    "            df_in[[col]]\n",
    "            .dropna()\n",
    "            .assign(**{col: df_in[col].str.split(\",\")})\n",
    "            .explode(col)\n",
    "        )\n",
    "        tmp[col] = tmp[col].astype(str).str.strip()\n",
    "        tmp = tmp[tmp[col] != \"\"]\n",
    "        return tmp\n",
    "    else:\n",
    "        tmp = df_in[[col]].dropna()\n",
    "        tmp[col] = tmp[col].astype(str).str.strip()\n",
    "        tmp = tmp[tmp[col] != \"\"]\n",
    "        return tmp\n",
    "\n",
    "# ---------- stacked 100% bars ----------\n",
    "\n",
    "for demo, question_list in comparison_pairs_by_demo.items():\n",
    "    for question in question_list:\n",
    "        try:\n",
    "            \n",
    "            q_is_multi = question in multiple_choice_questions\n",
    "            q_df = prepare_column(df, question, q_is_multi)\n",
    "\n",
    "            d_is_multi = demo in multiple_choice_demographics\n",
    "            d_df = prepare_column(df, demo, d_is_multi)\n",
    "\n",
    "            data = pd.concat([q_df, d_df], axis=1, join=\"inner\").dropna()\n",
    "\n",
    "            if data.empty:\n",
    "                print(f\"âš ï¸ No overlapping data for '{question}' x '{demo}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            ct = pd.crosstab(data[question], data[demo])\n",
    "\n",
    "            # order after defined list\n",
    "            if question in question_orders:\n",
    "                x_order = [v for v in question_orders[question] if v in ct.index]\n",
    "                remaining = [v for v in ct.index if v not in x_order]\n",
    "                ct = ct.reindex(x_order + remaining)  \n",
    "            else:\n",
    "                # numeric sorting\n",
    "                try:\n",
    "                    ct.index = pd.to_numeric(ct.index)\n",
    "                    ct = ct.sort_index()\n",
    "                except Exception:\n",
    "                    pass  \n",
    "\n",
    "            # order after defined list\n",
    "            if demo in question_orders:\n",
    "                d_order = [v for v in question_orders[demo] if v in ct.columns]\n",
    "                d_remaining = [v for v in ct.columns if v not in d_order]\n",
    "                ct = ct[d_order + d_remaining]\n",
    "            else:\n",
    "                # numeric sorting\n",
    "                try:\n",
    "                    new_cols = pd.Series(ct.columns).astype(float)\n",
    "                    ct = ct[sorted(ct.columns, key=lambda c: float(c))]\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            \n",
    "            ct_percent = ct.div(ct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "            # table output\n",
    "            print(f\"\\nðŸ“Š {question} â€“ stacked by {demo} (row-normalized to 100%)\")\n",
    "            print(\"Counts:\")\n",
    "            print(ct)\n",
    "            print(\"\\nPercent:\")\n",
    "            print(ct_percent.round(1))\n",
    "\n",
    "            # plot\n",
    "            title_and_colors = cross_tab_titles_and_colors.get(\n",
    "                (demo, question),\n",
    "                [f\"{question} â€“ distribution of {demo} within each answer\"]\n",
    "            )\n",
    "\n",
    "            plot_title = title_and_colors[0]\n",
    "\n",
    "            if len(title_and_colors) > 1:\n",
    "                # custom colors\n",
    "                colors = title_and_colors[1:]\n",
    "                ax = ct.plot(\n",
    "                    kind=\"bar\",\n",
    "                    stacked=True,\n",
    "                    figsize=(10, 6),\n",
    "                    color=colors,\n",
    "                    width=0.9\n",
    "                )\n",
    "            else:\n",
    "                # default palette\n",
    "                ax = ct.plot(\n",
    "                    kind=\"bar\",\n",
    "                    stacked=True,\n",
    "                    figsize=(10, 6),\n",
    "                    colormap=\"Set3\",\n",
    "                    width=0.9\n",
    "                )\n",
    "\n",
    "            ax.set_title(plot_title)\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_xlabel(question)\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.legend(title=demo, bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Failed for {question} x {demo}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4113a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CHI-SQUARE BLOCK (no plots)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "multiple_choice_demographics = {\n",
    "    \"Preferred Subjects\",\n",
    "    \"Least preferred Subjects\",\n",
    "    \"Most used subjects\",\n",
    "}\n",
    "\n",
    "def prepare_column(df_in, col, is_multi):\n",
    "    if col not in df_in.columns:\n",
    "        return pd.DataFrame(columns=[col])\n",
    "\n",
    "    if is_multi:\n",
    "        tmp = (\n",
    "            df_in[[col]]\n",
    "            .dropna()\n",
    "            .assign(**{col: df_in[col].astype(str).str.split(\",\")})\n",
    "            .explode(col)\n",
    "        )\n",
    "    else:\n",
    "        tmp = df_in[[col]].dropna()\n",
    "\n",
    "    tmp[col] = tmp[col].astype(str).str.strip()\n",
    "    tmp = tmp[tmp[col] != \"\"]\n",
    "    return tmp\n",
    "\n",
    "def order_crosstab(ct, question, demo):\n",
    "    # index\n",
    "    if question in question_orders:\n",
    "        x_order = [v for v in question_orders[question] if v in ct.index]\n",
    "        remaining = [v for v in ct.index if v not in x_order]\n",
    "        ct = ct.reindex(x_order + remaining)\n",
    "    else:\n",
    "        # numeric sorting if possible\n",
    "        try:\n",
    "            idx_num = pd.to_numeric(ct.index)\n",
    "            ct = ct.iloc[np.argsort(idx_num)]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # demographic columns\n",
    "    if demo in question_orders:\n",
    "        d_order = [v for v in question_orders[demo] if v in ct.columns]\n",
    "        d_remaining = [v for v in ct.columns if v not in d_order]\n",
    "        ct = ct[d_order + d_remaining]\n",
    "    else:\n",
    "        try:\n",
    "            _ = [float(c) for c in ct.columns]\n",
    "            ct = ct[sorted(ct.columns, key=lambda c: float(c))]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return ct\n",
    "\n",
    "def cramers_v(chi2, ct):\n",
    "    #Cramers' V for nominal association\n",
    "    n = ct.values.sum()\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    r, k = ct.shape\n",
    "    phi2 = chi2 / n\n",
    "    # bias correction \n",
    "    phi2corr = max(0, phi2 - ((k - 1)*(r - 1)) / (n - 1)) if n > 1 else np.nan\n",
    "    rcorr = r - ((r - 1)**2) / (n - 1) if n > 1 else r\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1) if n > 1 else k\n",
    "    denom = min(rcorr - 1, kcorr - 1)\n",
    "    return np.sqrt(phi2corr / denom) if denom > 0 else np.nan\n",
    "\n",
    "def chi_square_with_checks(ct):\n",
    "    # delete rows/cols with sum 0 \n",
    "    ct = ct.loc[ct.sum(axis=1) > 0, ct.sum(axis=0) > 0]\n",
    "    if ct.empty or (ct.shape[0] < 2 or ct.shape[1] < 2):\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"reason\": \"Contingency table too small or empty after filtering.\",\n",
    "            \"chi2\": np.nan, \"p\": np.nan, \"dof\": np.nan,\n",
    "            \"cramers_v\": np.nan, \"min_expected\": np.nan,\n",
    "            \"prop_expected_lt5\": np.nan, \"expected\": pd.DataFrame()\n",
    "        }\n",
    "\n",
    "    chi2, p, dof, expected = chi2_contingency(ct.values, correction=False)\n",
    "    expected_df = pd.DataFrame(expected, index=ct.index, columns=ct.columns)\n",
    "    min_exp = expected_df.values.min() if expected_df.size else np.nan\n",
    "    prop_lt5 = (expected_df.values < 5).mean() if expected_df.size else np.nan\n",
    "    v = cramers_v(chi2, ct)\n",
    "\n",
    "    return {\n",
    "        \"ok\": True,\n",
    "        \"reason\": \"\",\n",
    "        \"chi2\": chi2,\n",
    "        \"p\": p,\n",
    "        \"dof\": dof,\n",
    "        \"cramers_v\": v,\n",
    "        \"min_expected\": float(min_exp),\n",
    "        \"prop_expected_lt5\": float(prop_lt5),\n",
    "        \"expected\": expected_df\n",
    "    }\n",
    "\n",
    "#  build tables + chiÂ² results\n",
    "all_counts_long = []      \n",
    "all_perc_long   = []      \n",
    "all_tests       = []      # per test stats row\n",
    "\n",
    "for demo, question_list in comparison_pairs_by_demo.items():\n",
    "    for question in question_list:\n",
    "        try:\n",
    "            q_is_multi = question in multiple_choice_questions\n",
    "            d_is_multi = demo in multiple_choice_demographics\n",
    "\n",
    "            q_df = prepare_column(df, question, q_is_multi)\n",
    "            d_df = prepare_column(df, demo, d_is_multi)\n",
    "\n",
    "            # Auf Personenindex joinen (wie bei dir)\n",
    "            data = pd.concat([q_df, d_df], axis=1, join=\"inner\").dropna()\n",
    "            if data.empty:\n",
    "                print(f\"âš ï¸ No overlapping data for '{question}' x '{demo}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Kontingenztafel\n",
    "            ct = pd.crosstab(data[question], data[demo])\n",
    "\n",
    "            # Ordnung wie in deinem Plot-Code\n",
    "            ct = order_crosstab(ct, question, demo)\n",
    "\n",
    "            if ct.empty:\n",
    "                print(f\"âš ï¸ Empty crosstab for '{question}' x '{demo}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Prozent (zeilennormiert)\n",
    "            ct_percent = ct.div(ct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "            # ---- speichern (tidy) ----\n",
    "            counts_long = (\n",
    "                ct\n",
    "                .reset_index()\n",
    "                .melt(id_vars=ct.index.name or \"index\", var_name=\"col_cat\", value_name=\"count\")\n",
    "                .rename(columns={ct.index.name or \"index\": \"row_cat\"})\n",
    "            )\n",
    "            counts_long[\"demo\"] = demo\n",
    "            counts_long[\"question\"] = question\n",
    "            all_counts_long.append(counts_long)\n",
    "\n",
    "            perc_long = (\n",
    "                ct_percent\n",
    "                .reset_index()\n",
    "                .melt(id_vars=ct_percent.index.name or \"index\", var_name=\"col_cat\", value_name=\"percent_row\")\n",
    "                .rename(columns={ct_percent.index.name or \"index\": \"row_cat\"})\n",
    "            )\n",
    "            perc_long[\"demo\"] = demo\n",
    "            perc_long[\"question\"] = question\n",
    "            all_perc_long.append(perc_long)\n",
    "\n",
    "            # ---- ChiÂ²-Test + Diagnostik ----\n",
    "            test = chi_square_with_checks(ct)\n",
    "            all_tests.append({\n",
    "                \"demo\": demo,\n",
    "                \"question\": question,\n",
    "                \"n\": int(ct.values.sum()),\n",
    "                \"rows\": ct.shape[0],\n",
    "                \"cols\": ct.shape[1],\n",
    "                \"ok\": test[\"ok\"],\n",
    "                \"reason\": test[\"reason\"],\n",
    "                \"chi2\": test[\"chi2\"],\n",
    "                \"dof\": test[\"dof\"],\n",
    "                \"p\": test[\"p\"],\n",
    "                \"cramers_v\": test[\"cramers_v\"],\n",
    "                \"min_expected\": test[\"min_expected\"],\n",
    "                \"prop_expected_lt5\": test[\"prop_expected_lt5\"]\n",
    "            })\n",
    "\n",
    "            # ---- Konsolen-Ausgabe (kompakt) ----\n",
    "            print(f\"\\nðŸ“Š {question}  Ã—  {demo}\")\n",
    "            print(\"Counts:\")\n",
    "            print(ct)\n",
    "            print(\"\\nRow %:\")\n",
    "            print(ct_percent.round(1))\n",
    "\n",
    "            if test[\"ok\"]:\n",
    "                print(f\"\\nÏ‡Â²({test['dof']}) = {test['chi2']:.3f}, p = {test['p']:.4f},  CramÃ©râ€™s V = {test['cramers_v']:.3f}\")\n",
    "                print(f\"Assumptions: min(expected) = {test['min_expected']:.2f}, %cells<5 = {100*test['prop_expected_lt5']:.1f}%\")\n",
    "            else:\n",
    "                print(f\"\\nChi-square not run: {test['reason']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed for {question} x {demo}: {e}\")\n",
    "\n",
    "# ---------- dataframe outputs ----------\n",
    "crosstabs_counts_long = pd.concat(all_counts_long, ignore_index=True) if all_counts_long else pd.DataFrame(\n",
    "    columns=[\"demo\",\"question\",\"row_cat\",\"col_cat\",\"count\"]\n",
    ")\n",
    "crosstabs_perc_long = pd.concat(all_perc_long, ignore_index=True) if all_perc_long else pd.DataFrame(\n",
    "    columns=[\"demo\",\"question\",\"row_cat\",\"col_cat\",\"percent_row\"]\n",
    ")\n",
    "chi2_results = pd.DataFrame(all_tests, columns=[\n",
    "    \"demo\",\"question\",\"n\",\"rows\",\"cols\",\"ok\",\"reason\",\"chi2\",\"dof\",\"p\",\"cramers_v\",\"min_expected\",\"prop_expected_lt5\"\n",
    "]).sort_values([\"demo\",\"question\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n Finished chi-square run.\")\n",
    "print(f\"Results: {len(chi2_results)} tests.\")\n",
    "\n",
    "# ---------- excel-Export ----------\n",
    "EXPORT = True\n",
    "EXPORT_PATH = os.path.join(\"..\", \"Data/test_results\", \"crosstabs_and_chi2_results.xlsx\")\n",
    "\n",
    "if EXPORT:\n",
    "    with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as writer:\n",
    "        crosstabs_counts_long.to_excel(writer, index=False, sheet_name=\"crosstabs_counts\")\n",
    "        crosstabs_perc_long.to_excel(writer, index=False, sheet_name=\"crosstabs_row_percent\")\n",
    "        chi2_results.to_excel(writer, index=False, sheet_name=\"chi2_results\")\n",
    "    print(f\"ðŸ’¾ Exported to: {EXPORT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b42b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# POST-HOC ANALYSES (2Ã—2 & Spearman)\n",
    "# ==========================================\n",
    "\n",
    "import itertools\n",
    "from scipy.stats import fisher_exact, spearmanr\n",
    "\n",
    "multiple_choice_demographics = {\n",
    "    \"Preferred Subjects\",\n",
    "    \"Least preferred Subjects\",\n",
    "    \"Most used subjects\",\n",
    "}\n",
    "\n",
    "# Helpers  \n",
    "def prepare_column(df_in, col, is_multi):\n",
    "    if col not in df_in.columns:\n",
    "        return pd.DataFrame(columns=[col])\n",
    "    if is_multi:\n",
    "        tmp = (\n",
    "            df_in[[col]].dropna()\n",
    "            .assign(**{col: df_in[col].astype(str).str.split(\",\")})\n",
    "            .explode(col)\n",
    "        )\n",
    "    else:\n",
    "        tmp = df_in[[col]].dropna()\n",
    "    tmp[col] = tmp[col].astype(str).str.strip()\n",
    "    tmp = tmp[tmp[col] != \"\"]\n",
    "    return tmp\n",
    "\n",
    "def order_crosstab(ct, question, group):\n",
    "    # order of categories\n",
    "    if question in question_orders:\n",
    "        want = [v for v in question_orders[question] if v in ct.index]\n",
    "        rest = [v for v in ct.index if v not in want]\n",
    "        ct = ct.reindex(want + rest)\n",
    "    else:\n",
    "        try:\n",
    "            idx_num = pd.to_numeric(ct.index)\n",
    "            ct = ct.iloc[np.argsort(idx_num)]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if group in question_orders:\n",
    "        want = [v for v in question_orders[group] if v in ct.columns]\n",
    "        rest = [v for v in ct.columns if v not in want]\n",
    "        ct = ct[want + rest]\n",
    "    else:\n",
    "        try:\n",
    "            _ = [float(c) for c in ct.columns]\n",
    "            ct = ct[sorted(ct.columns, key=lambda c: float(c))]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return ct\n",
    "\n",
    "# ---------- 2Ã—2-Test (Fisher exact for small counts, else ChiÂ²) ----------\n",
    "def test_2x2(a, b, c, d, alternative=\"two-sided\", prefer=\"auto\", yates=False):\n",
    "    \n",
    "    table = np.array([[int(a), int(b)], [int(c), int(d)]], dtype=int)\n",
    "    row_sums = table.sum(axis=1)\n",
    "    col_sums = table.sum(axis=0)\n",
    "    if (row_sums[0] == 0) or (row_sums[1] == 0) or (col_sums[0] == 0) or (col_sums[1] == 0):\n",
    "        return {\n",
    "            \"method\": \"skip\", \"reason\": \"degenerate margins (zero row/column total)\",\n",
    "            \"p\": np.nan, \"chi2\": np.nan, \"dof\": 1, \"odds_ratio\": np.nan, \"min_expected\": 0.0,\n",
    "            \"table\": table,\n",
    "        }\n",
    "\n",
    "    N = table.sum()\n",
    "    expected = np.outer(row_sums, col_sums) / N\n",
    "    min_exp = expected.min()\n",
    "\n",
    "    method = \"chi2\"\n",
    "    if prefer == \"fisher\" or (prefer == \"auto\" and (min_exp < 5 or (table == 0).any())):\n",
    "        method = \"fisher\"\n",
    "\n",
    "    if method == \"fisher\":\n",
    "        orat, p = fisher_exact(table, alternative=alternative)\n",
    "        chi2_val, dof = np.nan, 1\n",
    "        odds_ratio = float(orat) if np.isfinite(orat) else np.nan\n",
    "    else:\n",
    "        try:\n",
    "            chi2_val, p, dof, _ = chi2_contingency(table, correction=yates)\n",
    "        except Exception:\n",
    "            # fallback on fisher\n",
    "            orat, p = fisher_exact(table, alternative=alternative)\n",
    "            chi2_val, dof = np.nan, 1\n",
    "            odds_ratio = float(orat) if np.isfinite(orat) else np.nan\n",
    "            return {\n",
    "                \"method\": \"fisher\", \"p\": float(p), \"chi2\": float(chi2_val), \"dof\": int(dof),\n",
    "                \"odds_ratio\": float(odds_ratio), \"min_expected\": float(min_exp), \"table\": table,\n",
    "            }\n",
    "        # Odds Ratio robust \n",
    "        a_, b_, c_, d_ = table.astype(float).ravel()\n",
    "        if 0 in (a_, b_, c_, d_):\n",
    "            a_, b_, c_, d_ = a_+0.5, b_+0.5, c_+0.5, d_+0.5\n",
    "        odds_ratio = (a_ * d_) / (b_ * c_)\n",
    "\n",
    "    return {\n",
    "        \"method\": method, \"p\": float(p), \"chi2\": float(chi2_val), \"dof\": int(dof),\n",
    "        \"odds_ratio\": float(odds_ratio), \"min_expected\": float(min_exp), \"table\": table,\n",
    "    }\n",
    "\n",
    "# ---------- Nominal Ã— Nominal: pairwise 2Ã—2-Tests  ----------\n",
    "def posthoc_nominal(question, group, prefer=\"auto\", yates=False, alternative=\"two-sided\"):\n",
    "    # handling of MC-questions\n",
    "    q_is_multi = question in multiple_choice_questions\n",
    "    g_is_multi = (group in multiple_choice_demographics) or (group in multiple_choice_questions)\n",
    "\n",
    "    q_df = prepare_column(df, question, q_is_multi)\n",
    "    g_df = prepare_column(df, group, g_is_multi)\n",
    "\n",
    "    data = pd.concat([q_df, g_df], axis=1, join=\"inner\").dropna()\n",
    "    if data.empty:\n",
    "        return pd.DataFrame(columns=[\"question\",\"group\",\"row_cat\",\"g1\",\"g2\",\"method\",\"p\",\"chi2\",\"dof\",\"odds_ratio\",\"min_expected\",\"n_g1\",\"n_g2\",\"x_g1\",\"x_g2\"])\n",
    "\n",
    "    ct = pd.crosstab(data[question], data[group])\n",
    "    if not ct.columns.is_unique: ct = ct.T.groupby(level=0).sum().T\n",
    "    if not ct.index.is_unique:   ct = ct.groupby(level=0).sum()\n",
    "    ct = order_crosstab(ct, question, group)\n",
    "\n",
    "    totals = ct.sum(axis=0)\n",
    "    results = []\n",
    "\n",
    "    for row_cat in ct.index:\n",
    "        for g1, g2 in itertools.combinations(ct.columns, 2):\n",
    "            a = int(ct.loc[row_cat, g1]); n1 = int(totals[g1]); b = n1 - a\n",
    "            c = int(ct.loc[row_cat, g2]); n2 = int(totals[g2]); d = n2 - c\n",
    "            res = test_2x2(a, b, c, d, alternative=alternative, prefer=prefer, yates=yates)\n",
    "\n",
    "            results.append({\n",
    "                \"question\": question, \"group\": group, \"row_cat\": row_cat,\n",
    "                \"g1\": g1, \"g2\": g2,\n",
    "                \"method\": res[\"method\"], \"p\": res[\"p\"], \"chi2\": res[\"chi2\"], \"dof\": res[\"dof\"],\n",
    "                \"odds_ratio\": res[\"odds_ratio\"], \"min_expected\": res[\"min_expected\"],\n",
    "                \"n_g1\": n1, \"n_g2\": n2, \"x_g1\": a, \"x_g2\": c,\n",
    "                \"note\": res.get(\"reason\",\"\")\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ---------- Ordinal Ã— Ordinal: Spearman-Trend  ----------\n",
    "def map_to_numeric_flexible(series, question):\n",
    "    s = series.astype(str)\n",
    "    # mapping\n",
    "    if question in likert_mapping:\n",
    "        mp = {str(k): v for k, v in likert_mapping[question].items()}\n",
    "        out = s.map(mp)\n",
    "        if out.notna().any():\n",
    "            return out.astype(float)\n",
    "    # order\n",
    "    if question in question_orders:\n",
    "        order = [str(x) for x in question_orders[question]]\n",
    "        mapper = {cat: i for i, cat in enumerate(order)}\n",
    "        out = s.map(mapper)\n",
    "        if out.notna().any():\n",
    "            return out.astype(float)\n",
    "    # Scales\n",
    "    common_orders = [\n",
    "        [\"Nie\",\"Selten\",\"Manchmal\",\"Oft\",\"Sehr oft\"],\n",
    "        [\"Nie\",\"Seltener\",\"Etwa 1 Mal pro Woche\",\"Mehrmals pro Woche\",\"TÃ¤glich\"],\n",
    "        [\"Gar nicht\",\"Eher wenig\",\"Teils/teils\",\"Eher gut\",\"Sehr gut\"],\n",
    "        [\"Gar nicht verlÃ¤sslich\",\"Wenig verlÃ¤sslich\",\"Unsicher / Ich habe keine Meinung\",\n",
    "         \"Teils/teils\",\"Eher verlÃ¤sslich\",\"Sehr verlÃ¤sslich\"],\n",
    "        [\"Kein VerstÃ¤ndnis\",\"Schlechtes VerstÃ¤ndnis\",\"MittelmÃ¤ssiges VerstÃ¤ndnis\",\"Gutes VerstÃ¤ndnis\",\"VÃ¶lliges VerstÃ¤ndnis\"],\n",
    "        [\"StÃ¶rt mich sehr\",\"StÃ¶rt mich ein wenig\",\"Neutral / Mir egal\",\"Finde ich gut\", \"Finde ich sehr gut\"]\n",
    "    ]\n",
    "    su = set(s.unique())\n",
    "    for order in common_orders:\n",
    "        if su.issubset(set(order)):\n",
    "            mapper = {cat: i for i, cat in enumerate(order)}\n",
    "            return s.map(mapper).astype(float)\n",
    "    # fallback numeric\n",
    "    return pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "def make_ordered_group(series, name):\n",
    "    s = series.astype(str)\n",
    "    uniq = sorted(s.unique())\n",
    "    if name in question_orders:\n",
    "        desired = [str(x) for x in question_orders[name]]\n",
    "        cats = [c for c in desired if c in s.unique()] + [c for c in uniq if c not in desired]\n",
    "    else:\n",
    "        try:\n",
    "            nums = sorted({float(x) for x in s.unique()})\n",
    "            cats = [str(int(x)) if float(x).is_integer() else str(x) for x in nums]\n",
    "        except Exception:\n",
    "            cats = uniq\n",
    "    return pd.Categorical(s, categories=cats, ordered=True)\n",
    "\n",
    "def posthoc_trend_spearman(question, group):\n",
    "    #Spearman for ordinal pairs\n",
    "\n",
    "    # Skip, if question is MC\n",
    "    if (question in multiple_choice_questions and \"(Count)\" not in question) or \\\n",
    "       (group in multiple_choice_questions and \"(Count)\" not in group):\n",
    "        print(f\" Spearman skipped for {question} Ã— {group}\")\n",
    "        return pd.DataFrame(columns=[\"question\",\"group\",\"n\",\"rho\",\"p\",\"direction\"])\n",
    "\n",
    "    if question not in df.columns or group not in df.columns:\n",
    "        return pd.DataFrame(columns=[\"question\",\"group\",\"n\",\"rho\",\"p\",\"direction\"])\n",
    "\n",
    "    data = df[[question, group]].dropna().copy()\n",
    "    if data.empty:\n",
    "        return pd.DataFrame(columns=[\"question\",\"group\",\"n\",\"rho\",\"p\",\"direction\"])\n",
    "\n",
    "    x = map_to_numeric_flexible(data[question], question)\n",
    "    g_cat = make_ordered_group(data[group], group)\n",
    "    codes = pd.Series(g_cat).cat.codes.astype(float)\n",
    "\n",
    "    valid = (~x.isna()) & (~codes.isna())\n",
    "    if not valid.any():\n",
    "        return pd.DataFrame(columns=[\"question\",\"group\",\"n\",\"rho\",\"p\",\"direction\"])\n",
    "\n",
    "    rho, p = spearmanr(x[valid].values, codes[valid].values)\n",
    "    direction = \"positive\" if rho > 0 else (\"negative\" if rho < 0 else \"zero\")\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"question\": question, \"group\": group, \"n\": int(valid.sum()),\n",
    "        \"rho\": float(rho), \"p\": float(p), \"direction\": direction\n",
    "    }])\n",
    "\n",
    "# run all tests\n",
    "all_nominal = []\n",
    "for (q, g) in nominal_posthoc_pairs_demo:\n",
    "    try:\n",
    "        df_res = posthoc_nominal(q, g, prefer=\"auto\", yates=False, alternative=\"two-sided\")\n",
    "        if not df_res.empty:\n",
    "            all_nominal.append(df_res)\n",
    "            print(f\"Nominal 2Ã—2 computed for {q} Ã— {g} ({len(df_res)} Tests).\")\n",
    "        else:\n",
    "            print(f\" No data for {q} Ã— {g}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed nominal 2Ã—2 for {q} Ã— {g}: {e}\")\n",
    "\n",
    "nominal_posthoc_results = (\n",
    "    pd.concat(all_nominal, ignore_index=True) if all_nominal\n",
    "    else pd.DataFrame(columns=[\"question\",\"group\",\"row_cat\",\"g1\",\"g2\",\"method\",\"p\",\"chi2\",\"dof\",\"odds_ratio\",\"min_expected\",\"n_g1\",\"n_g2\",\"x_g1\",\"x_g2\",\"note\"])\n",
    ")\n",
    "\n",
    "all_trend = []\n",
    "for (q, g) in ordinal_posthoc_pairs_demo:\n",
    "    try:\n",
    "        trend = posthoc_trend_spearman(q, g)\n",
    "        if not trend.empty:\n",
    "            all_trend.append(trend)\n",
    "            print(f\"Spearman trend computed for {q} Ã— {g}.\")\n",
    "        else:\n",
    "            print(f\" No data for Spearman {q} Ã— {g}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed Spearman for {q} Ã— {g}: {e}\")\n",
    "\n",
    "trend_results = (\n",
    "    pd.concat(all_trend, ignore_index=True) if all_trend\n",
    "    else pd.DataFrame(columns=[\"question\",\"group\",\"n\",\"rho\",\"p\",\"direction\"])\n",
    ")\n",
    "\n",
    "print(f\"Nominal 2Ã—2 tests: {len(nominal_posthoc_results)} | Spearman trends: {len(trend_results)}\")\n",
    "\n",
    "# export \n",
    "EXPORT = True\n",
    "EXPORT_PATH = os.path.join(\"..\", \"Data/test_results\", \"posthoc_results.xlsx\")\n",
    "if EXPORT:\n",
    "    with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as writer:\n",
    "        nominal_posthoc_results.to_excel(writer, index=False, sheet_name=\"nominal_pairwise_2x2\")\n",
    "        trend_results.to_excel(writer, index=False, sheet_name=\"spearman_trend\")\n",
    "    print(f\" Exported to: {EXPORT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph: AI USAGE BY AGE --------------------------\n",
    "\n",
    "# counts\n",
    "counts = pd.DataFrame({\n",
    "    13: [2, 7, 14, 9, 3],\n",
    "    14: [1, 12, 14, 14, 4],\n",
    "    15: [9, 11, 3, 4, 0],\n",
    "    16: [10, 14, 4, 4, 3],\n",
    "    17: [21, 15, 0, 0, 0],\n",
    "    18: [9, 5, 3, 0, 0],\n",
    "    19: [4, 4, 0, 0, 0],\n",
    "}, index=[\n",
    "    \"Daily\",\n",
    "    \"Several times per week\",\n",
    "    \"About once per week\",\n",
    "    \"Rarely\",\n",
    "    \"Never\"\n",
    "])\n",
    "\n",
    "# age order\n",
    "ages = [13, 14, 15, 16, 17, 18, 19]\n",
    "counts = counts[ages]\n",
    "\n",
    "# order and naming of categories\n",
    "order = [\"Daily\", \"Several times per week\", \"About once per week\", \"Rarely\", \"Never\"]\n",
    "counts = counts.reindex(order)\n",
    "\n",
    "# colours\n",
    "colors = plt.cm.Blues([0.90, 0.75, 0.60, 0.45, 0.30])\n",
    "\n",
    "# plot \n",
    "ax = counts.T.plot(kind=\"bar\", stacked=True, figsize=(10, 6),\n",
    "                   color=colors, width=0.9)\n",
    "\n",
    "ax.set_title(\"AI usage (school + free time) by age\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Number of respondents\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Age\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1],\n",
    "          title=\"Usage frequency\",\n",
    "          loc=\"upper right\",    # innerhalb der Grafik\n",
    "          fontsize=12, title_fontsize=13,\n",
    "          framealpha=0.9)       # halbtransparentes KÃ¤stchen\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda91383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph: CONCERNS AI BY AGE -----------------\n",
    "\n",
    "# data\n",
    "data = {\n",
    "    13: [6, 11, 18],\n",
    "    14: [22, 10, 13],\n",
    "    15: [9, 10, 8],\n",
    "    16: [14, 15, 6],\n",
    "    17: [17, 17, 2],\n",
    "    18: [6, 8, 3],\n",
    "    19: [5, 3, 0],\n",
    "}\n",
    "index = [\"Yes\", \"No\", \"Never thought about it\"]\n",
    "counts = pd.DataFrame(data, index=index)\n",
    "\n",
    "# age order\n",
    "ages = [13, 14, 15, 16, 17, 18, 19]\n",
    "counts = counts[ages]\n",
    "\n",
    "# order for stacking\n",
    "order = [\"Yes\", \"No\", \"Never thought about it\"]\n",
    "counts = counts.reindex(order)\n",
    "\n",
    "# set colours\n",
    "colors = {\n",
    "    \"Yes\": \"green\",\n",
    "    \"No\": \"red\",\n",
    "    \"Never thought about it\": \"#4A90E2\" \n",
    "}\n",
    "\n",
    "# Plot\n",
    "ax = counts.T.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(10, 6),\n",
    "    color=[colors[o] for o in order],\n",
    "    width=0.9\n",
    ")\n",
    "\n",
    "# title and axis\n",
    "ax.set_title(\"Concerns about AI by age\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Number of respondents\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Age\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels,\n",
    "          title=\"Concerns\",\n",
    "          loc=\"upper right\",\n",
    "          fontsize=12, title_fontsize=13,\n",
    "          framealpha=0.9)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- graph: AI usage by hours per week spent for school\n",
    "\n",
    "# data\n",
    "data = {\n",
    "    \"0-1 hours/week\":     [3, 8, 7, 11, 4],\n",
    "    \"2-5 hours/week\":     [5, 25, 41, 19, 17],\n",
    "    \"More than 5 hours/week\": [3, 5, 16, 15, 14]\n",
    "}\n",
    "index = [\"Never\", \"Rarely\", \"Sometimes\", \"Often\", \"Very often\"]\n",
    "counts = pd.DataFrame(data, index=index)\n",
    "\n",
    "# set x-axis\n",
    "order_x = [\"Very often\", \"Often\", \"Sometimes\", \"Rarely\", \"Never\"]\n",
    "counts = counts.reindex(order_x)\n",
    "\n",
    "# correct order\n",
    "order_stack = [\"More than 5 hours/week\", \"2-5 hours/week\", \"0-1 hours/week\"]\n",
    "counts = counts[order_stack]\n",
    "\n",
    "# set colours\n",
    "colors = {\n",
    "    \"More than 5 hours/week\": \"#0c3d86\",\n",
    "    \"2-5 hours/week\": \"#3181b6\",\n",
    "    \"0-1 hours/week\": \"#76b6f1\"\n",
    "}\n",
    "\n",
    "# plot\n",
    "ax = counts.plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(10, 6),\n",
    "    color=[colors[c] for c in order_stack], width=0.9\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_title(\"AI usage frequency for education by hours per week spent for school in free time\",\n",
    "             fontsize=16, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Number of respondents\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Usage frequency\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# adjust legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legend_display = [\"0-1 hours/week\", \"2-5 hours/week\", \"More than 5 hours/week\"]  # hell â†’ dunkel\n",
    "lookup = {lab: h for h, lab in zip(handles, labels)}\n",
    "ax.legend([lookup[l] for l in legend_display], legend_display,\n",
    "          title=\"Hours per week\", loc=\"upper right\",\n",
    "          fontsize=12, title_fontsize=13, framealpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9331588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph: Most used subjects by gender \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# correct order\n",
    "subjects = [\n",
    "    \"History\", \"German\", \"Mathematics\", \"French\", \"Geography\",\n",
    "    \"Biology\", \"Chemistry\", \"English\", \"Physics\"\n",
    "]\n",
    "\n",
    "# percentages for each \n",
    "data = {\n",
    "    \"Male\":   [17.3, 14.7, 14.1, 11.5,  8.9,  6.3,  7.3,  5.8,  5.2],\n",
    "    \"Female\": [19.8, 11.8, 11.4, 12.2, 11.0, 10.1,  7.6,  7.6,  4.6],\n",
    "    \"No answer\": [12.5, 12.5, 18.8, 12.5, 18.8, 0.0, 6.2, 0.0, 18.8],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=subjects)\n",
    "\n",
    "# 3 bars per subjects\n",
    "ax = df.plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(11, 4.5),\n",
    "    width=0.85,\n",
    "    color=[\"#2b8cbe\", \"#de2d26\", \"#2ca25f\"]  # male = blue, female = red, no answer = green\n",
    ")\n",
    "\n",
    "ax.set_title(\"Most used subjects â€“ by gender\", fontsize=14)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.set_xlabel(\"Subject\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(False)\n",
    "ax.legend(title=\"Gender\", loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
